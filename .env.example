# Database configuration
DATABASE_URL=postgresql://app:password@db:5432/research
STORAGE_DIR=/data/uploads

# External services
GROBID_URL=http://grobid:8070
OLLAMA_URL=http://ollama:11434

# N8N configuration
N8N_BASIC_AUTH_ACTIVE=true
N8N_BASIC_AUTH_USER=admin
N8N_BASIC_AUTH_PASSWORD=admin123
N8N_ENCRYPTION_KEY=your-encryption-key-here-change-in-production
N8N_HOST=localhost
N8N_PORT=5678
N8N_INGEST_SECRET=your-secret-here-change-in-production

# CORS configuration
CORS_ORIGINS=http://localhost:5173

# Space-separated list of models to pre-pull. Pick ONE of these depending on your machine:
# - llama3.2:3b-instruct-q4_K_M (better quality, ~2GB download)
# - tinyllama:latest (very small, lowest resource usage)
# - can pull anyother model you want to do an experiment with
OLLAMA_MODELS=llama3.2:3b-instruct-q4_K_M